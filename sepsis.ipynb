{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules and Library Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os  # For interacting with the operating system\n",
    "import numpy as np  # For numerical operations\n",
    "import pygal  # For generating interactive charts\n",
    "import pickle  # For serializing and deserializing Python objects\n",
    "from prettytable import PrettyTable  # For displaying tabular data in a visually appealing ASCII format\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # For splitting data and performing grid search\n",
    "from sklearn.preprocessing import StandardScaler  # For standardizing features\n",
    "from sklearn.linear_model import LogisticRegression  # For logistic regression modeling\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score  # For model evaluation metrics\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import seaborn as sns  # For statistical data visualization\n",
    "import matplotlib.pyplot as plt  # For creating static, animated, and interactive visualizations\n",
    "from wtforms import fields  # For creating web forms\n",
    "import altair as alt  # For declarative statistical visualization library\n",
    "from wtforms import SelectField\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "current_dir = os.getcwd()\n",
    "train_data_path = os.path.join(current_dir, 'datasets', 'Paitients_Files_Train.csv')\n",
    "test_data_path = os.path.join(current_dir, 'datasets', 'Paitients_Files_Test.csv')\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick look at the shape of our dataset\n",
    "print(\"Shape of Training Dataset:\", train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the head of our dataset\n",
    "print(\"Head of Training Dataset:\")\n",
    "print(train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of Columns\n",
    "column_description = {\n",
    "    'ID': 'Unique number to represent patient ID',\n",
    "    'PRG': 'Plasma glucose',\n",
    "    'PL': 'Blood Work Result-1 (mu U/ml)',\n",
    "    'PR': 'Blood Pressure (mm Hg)',\n",
    "    'SK': 'Blood Work Result-2 (mm)',\n",
    "    'TS': 'Blood Work Result-3 (mu U/ml)',\n",
    "    'M11': 'Body mass index (weight in kg/(height in m)^2)',\n",
    "    'BD2': 'Blood Work Result-4 (mu U/ml)',\n",
    "    'Age': 'Patients age (years)',\n",
    "    'Insurance': 'If a patient holds a valid insurance card',\n",
    "    'Sepssis': 'Target: Positive if a patient in ICU will develop sepsis, Negative otherwise'\n",
    "}\n",
    "print(\"Description of Columns:\")\n",
    "for column, description in column_description.items():\n",
    "    print(f\"{column}: {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the columns in the dataset and their data types\n",
    "print(\"Information about Training Dataset:\")\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get more details about the features of our data\n",
    "print(\"Description of Training Dataset:\")\n",
    "print(train_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values in Training Dataset:\")\n",
    "print(train_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = train_data.duplicated()\n",
    "print(\"Number of duplicates:\", duplicates.sum())\n",
    "print(\"Duplicate rows:\")\n",
    "print(train_data[duplicates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unique values for each column\n",
    "for column in train_data.columns:\n",
    "    unique_values = train_data[column].unique()\n",
    "    print(f\"Unique values in {column}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate outliers\n",
    "outliers = {}\n",
    "\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].dtype != 'object':\n",
    "        Q1 = train_data[col].quantile(0.25)\n",
    "        Q3 = train_data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        col_outliers = train_data[(train_data[col] < lower_bound) | (train_data[col] > upper_bound)][col].tolist()\n",
    "        outliers[col] = col_outliers\n",
    "\n",
    "# Display outliers\n",
    "for col, col_outliers in outliers.items():\n",
    "    print(f\"Outliers in {col}: {col_outliers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here are the issues identified in the dataset and potential solutions:\n",
    "\n",
    "### Data Types:\n",
    "\n",
    "- The 'ID' column is of type object, which is suitable for unique identifiers.\n",
    "- The 'Sepssis' column is also of type object, which suggests it might contain categorical data.\n",
    "- There is an excess of zero values in every column.\n",
    "- The target variable 'Sepsis' may exhibit imbalanced class distribution.\n",
    "- Several numerical columns contain numerous outliers.\n",
    "- Potential correlations among predictor variables may lead to multicollinearity.\n",
    "\n",
    "### Outliers:\n",
    "\n",
    "Outliers are detected in several numerical columns like 'PRG', 'PR', 'SK', 'TS', 'M11', 'BD2', and 'Age'. Outliers can significantly affect model performance and need to be addressed. One approach could be to cap or clip the outliers to a certain threshold, or using techniques like Winsorization to replace them with more reasonable values.\n",
    "\n",
    "### Missing Values:\n",
    "\n",
    "No missing values are reported in the dataset, which is a good sign. However, it's essential to verify if missing values are encoded differently, such as using placeholder values like '-1' or '999'.\n",
    "\n",
    "### Duplicates:\n",
    "\n",
    "No duplicate rows are reported, which is also a positive finding. Duplicate rows, if present, need to be removed to prevent bias in the analysis.\n",
    "\n",
    "### Categorical Data Encoding:\n",
    "\n",
    "The 'Sepssis' column appears to contain categorical data. If it's binary (yes/no), it could be encoded as 0 and 1 for no and yes, respectively, or using one-hot encoding if there are more than two categories.\n",
    "\n",
    "### Column Names:\n",
    "\n",
    "The column names are not very descriptive. It's recommended to rename the columns to more meaningful names for better clarity and interpretability.\n",
    "\n",
    "### Data Distribution:\n",
    "\n",
    "It's essential to visualize the distribution of each numerical feature to understand the data better and identify any skewness or anomalies that may require further investigation.\n",
    "\n",
    "### Scaling:\n",
    "\n",
    "Depending on the algorithms to be used, it might be necessary to scale the numerical features to ensure they contribute equally to the model fitting process.\n",
    "\n",
    "### Data Interpretation:\n",
    "\n",
    "Understanding the context of the data is crucial. Domain knowledge can help in interpreting the features correctly and making informed decisions during data preprocessing and analysis.\n",
    "\n",
    "By addressing these issues, the dataset can be prepared for further analysis and modeling, ensuring better performance and more reliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis:\n",
    "- Null Hypothesis: There is no association between the presence of comorbidities and the likelihood of developing Sepsis among patients in the dataset.\n",
    "- Alternate Hypothesis: Patients with underlying comorbidities are more likely to develop Sepsis compared to those without comorbidities within the dataset.\n",
    "\n",
    "### Analytical Questions:\n",
    "1. What is the prevalence of comorbidities among patients diagnosed with Sepsis compared to those without Sepsis?\n",
    "2. Are specific comorbidities more commonly observed among patients diagnosed with Sepsis?\n",
    "3. How does the distribution of comorbidities vary across different age groups in the dataset?\n",
    "4. What are the demographic characteristics (e.g., age, insurance status) of patients with and without comorbidities?\n",
    "5. Is there a correlation between the number of comorbidities a patient has and the likelihood of developing Sepsis within the dataset?\n",
    "6. Do patients with specific comorbidities exhibit a higher risk of developing severe forms of Sepsis?\n",
    "7. How do the presence of comorbidities impact the prognosis and outcomes of Sepsis patients within the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named 'data'\n",
    "train_data.drop(columns=['ID'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Rename the columns\n",
    "train_data = train_data.rename(columns={\n",
    "    \"PRG\": \"Plasma_glucose\",\n",
    "    \"PL\": \"Blood_Work_R1\",\n",
    "    \"PR\": \"Blood_Pressure\",\n",
    "    \"SK\": \"Blood_Work_R2\",\n",
    "    \"TS\": \"Blood_Work_R3\",\n",
    "    \"M11\": \"BMI\",\n",
    "    \"BD2\": \"Blood_Work_R4\",\n",
    "    \"Age\": \"Patient_age\",\n",
    "    \"Sepssis\": \"Target_Sepsis\"\n",
    "})\n",
    "\n",
    "# Replace zeros in each column with the median value\n",
    "columns_with_zeros = ['Plasma_glucose', 'Blood_Work_R1', 'Blood_Pressure', 'Blood_Work_R2', 'Blood_Work_R3', 'BMI', 'Blood_Work_R4']\n",
    "for col in columns_with_zeros:\n",
    "    median_val = train_data[col].median()\n",
    "    train_data[col] = train_data[col].replace(0, median_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = train_data.select_dtypes(include=[np.number]).columns\n",
    "num_df = train_data[numeric_columns]\n",
    "\n",
    "Q1 = num_df.quantile(0.25)\n",
    "Q3 = num_df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = ((num_df < (Q1 - 1.5 * IQR)) | (num_df > (Q3 + 1.5 * IQR))).any()\n",
    "\n",
    "outliers_df = outliers.to_frame().T\n",
    "print(outliers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the numeric_columns except Insurance have outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Q1, Q3, and IQR\n",
    "Q1 = num_df.quantile(0.25)\n",
    "Q3 = num_df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the DataFrame to remove outliers\n",
    "cleaned_df = num_df[~((num_df < lower_bound) | (num_df > upper_bound)).any(axis=1)]\n",
    "\n",
    "# Print the shape of the cleaned DataFrame\n",
    "print(\"Shape of cleaned DataFrame:\", cleaned_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the boxplot\n",
    "train_data.boxplot()\n",
    "\n",
    "# Rotate x-axis labels by 45 degrees\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style for the plot\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "# Create a grid of 3 by 3 subplots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "# Flatten the axes array\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot histograms for each numerical column\n",
    "for i, col in enumerate(cleaned_df.columns):\n",
    "    sns.histplot(cleaned_df[col], kde=True, ax=axes[i])\n",
    "    axes[i].set_title(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Target_Sepsis' column to boolean values\n",
    "train_data['Target_Sepsis'] = train_data['Target_Sepsis'].map({'Positive': True, 'Negative': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive comorbidity count based on the presence of comorbidities\n",
    "train_data['Comorbidity_Count'] = train_data[['Plasma_glucose', 'Blood_Work_R1', 'Blood_Pressure', \n",
    "                                              'Blood_Work_R2', 'Blood_Work_R3', 'BMI', \n",
    "                                              'Blood_Work_R4']].gt(0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create separate dataframes for positive and negative cases\n",
    "positive_cases = train_data[train_data['Target_Sepsis']]\n",
    "negative_cases = train_data[~train_data['Target_Sepsis']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print columns for positive cases\n",
    "print(\"Columns for positive cases:\")\n",
    "print(positive_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print columns for negative cases\n",
    "print(\"\\nColumns for negative cases:\")\n",
    "print(negative_cases[['Plasma_glucose', 'Blood_Work_R1', 'Blood_Pressure', 'Blood_Work_R2', 'Blood_Work_R3']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of comorbidities among positive cases\n",
    "positive_comorbidities = positive_cases.iloc[:, [1, 2, 3, 4, 5]]\n",
    "positive_comorbidities_describe = positive_comorbidities.describe()\n",
    "\n",
    "# Create a PrettyTable instance\n",
    "table = PrettyTable()\n",
    "\n",
    "# Set column names\n",
    "table.field_names = positive_comorbidities_describe.columns\n",
    "\n",
    "# Add data rows to the table\n",
    "for row in positive_comorbidities_describe.itertuples(index=False):\n",
    "    table.add_row(row)\n",
    "\n",
    "# Display the table\n",
    "print(\"Distribution of comorbidities among positive cases:\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of comorbidities among negative cases\n",
    "negative_comorbidities = negative_cases.iloc[:, [1, 2, 3, 4, 5]]\n",
    "negative_comorbidities_describe = negative_comorbidities.describe()\n",
    "\n",
    "# Create a PrettyTable instance\n",
    "table = PrettyTable()\n",
    "\n",
    "# Set column names\n",
    "table.field_names = negative_comorbidities_describe.columns\n",
    "\n",
    "# Add data rows to the table\n",
    "for row in negative_comorbidities_describe.itertuples(index=False):\n",
    "    table.add_row(row)\n",
    "\n",
    "# Display the table\n",
    "print(\"Distribution of comorbidities among negative cases:\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of comorbidities by age group\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='Patient_age', y='Comorbidity_Count', hue='Target_Sepsis', data=train_data)\n",
    "plt.title('Distribution of Comorbidities by Age Group and Sepsis Diagnosis')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Comorbidity Count')\n",
    "plt.legend(title='Sepsis Diagnosis', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze demographic characteristics of patients with and without comorbidities\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='Insurance', hue='Comorbidity_Count', data=train_data)\n",
    "plt.title('Insurance Status of Patients with Different Comorbidity Counts')\n",
    "plt.xlabel('Insurance Status')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Comorbidity Count', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare prevalence of comorbidities among positive and negative cases\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "\n",
    "for i, col in enumerate(positive_comorbidities.columns):\n",
    "    sns.histplot(positive_comorbidities[col], kde=True, ax=axes[0, i], color='blue', label='Sepsis')\n",
    "    sns.histplot(negative_comorbidities[col], kde=True, ax=axes[1, i], color='red', label='No Sepsis')\n",
    "    axes[0, i].set_title(f'{col} Distribution (Sepsis)')\n",
    "    axes[1, i].set_title(f'{col} Distribution (No Sepsis)')\n",
    "    axes[0, i].legend()\n",
    "    axes[1, i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "sns.pairplot(cleaned_df)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cleaned_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean comorbidity count for each Sepsis diagnosis category\n",
    "sepsis_comorbidity_mean = train_data.groupby('Target_Sepsis')['Comorbidity_Count'].mean()\n",
    "\n",
    "# Create a PrettyTable object\n",
    "table = PrettyTable()\n",
    "\n",
    "# Define table columns\n",
    "table.field_names = [\"Sepsis Diagnosis\", \"Mean Comorbidity Count\"]\n",
    "\n",
    "# Add rows to the table\n",
    "for sepsis_status, mean_count in sepsis_comorbidity_mean.items():\n",
    "    table.add_row([sepsis_status, mean_count])\n",
    "\n",
    "# Set alignment for columns\n",
    "table.align[\"Sepsis Diagnosis\"] = \"l\"\n",
    "table.align[\"Mean Comorbidity Count\"] = \"r\"\n",
    "\n",
    "# Print the table\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the correlation between comorbidities count and Sepsis diagnosis\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Target_Sepsis', y='Comorbidity_Count', data=train_data)\n",
    "plt.title('Association between Comorbidity Count and Sepsis Diagnosis')\n",
    "plt.xlabel('Sepsis Diagnosis')\n",
    "plt.ylabel('Comorbidity Count')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
